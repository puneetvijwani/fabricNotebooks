{"cells":[{"cell_type":"markdown","source":["#### This notebook demonstrates how to load data from Azure Open Datasets into Delta Lake\r\n","#### and how to load data using comparison method incrementally month by month.\r\n"," \r\n","#### The particular dataset being used in this example is the New York City Green Taxi dataset."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# Loading the necessary libraries\n","from pyspark.sql import SparkSession\n","from azureml.opendatasets import NycTlcGreen\n","from datetime import datetime\n","from dateutil import parser,relativedelta\n","import pyspark.sql.functions as f\n","from pyspark.sql.functions import year, month, dayofmonth, dayofweek, hour, to_date, col, quarter, explode, sequence, expr,current_timestamp\n","from pyspark.sql.types import StructType, StructField, IntegerType, TimestampType, DoubleType, StringType\n","from delta.tables import DeltaTable\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"29fb1d8f-d200-4a2f-b7fb-8dad3aa89d5f","statement_id":9,"state":"finished","livy_statement_state":"available","queued_time":"2023-06-19T18:18:02.9112946Z","session_start_time":null,"execution_start_time":"2023-06-19T18:18:03.6805952Z","execution_finish_time":"2023-06-19T18:18:06.3495185Z","spark_jobs":{"numbers":{"SUCCEEDED":0,"UNKNOWN":0,"RUNNING":0,"FAILED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"bb7e6996-0621-481d-b30c-342dbdda81b0"},"text/plain":"StatementMeta(, 29fb1d8f-d200-4a2f-b7fb-8dad3aa89d5f, 9, Finished, Available)"},"metadata":{}}],"execution_count":5,"metadata":{}},{"cell_type":"markdown","source":["##### We set the Parquet Vorder to be enabled. This is a performance setting that can help speed up reading Parquet files in one lake"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["%%sql \r\n","SET spark.sql.parquet.vorder.enabled=TRUE"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"29fb1d8f-d200-4a2f-b7fb-8dad3aa89d5f","statement_id":8,"state":"finished","livy_statement_state":"available","queued_time":"2023-06-19T18:17:55.3600266Z","session_start_time":null,"execution_start_time":"2023-06-19T18:17:56.0939143Z","execution_finish_time":"2023-06-19T18:17:56.9945487Z","spark_jobs":{"numbers":{"SUCCEEDED":0,"UNKNOWN":0,"RUNNING":0,"FAILED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"a5872514-204d-466d-8e63-f8ab445238e4"},"text/plain":"StatementMeta(, 29fb1d8f-d200-4a2f-b7fb-8dad3aa89d5f, 8, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":4,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[{"name":"key","type":"string","nullable":false,"metadata":{}},{"name":"value","type":"string","nullable":false,"metadata":{}}]},"data":[["spark.sql.parquet.vorder.enabled","TRUE"]]},"text/plain":"<Spark SQL result set with 1 rows and 2 fields>"},"metadata":{}}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false}},{"cell_type":"code","source":["delta_load = 1 # Set to 1 for incremental load, 0 for full load\r\n","start_date_param = '2014-05-01' # Set your desired start date\r\n","end_date_param = '2018-06-06' # Set your desired end date"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-06-18T19:43:06.1956375Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"9d5dbba8-8ab2-4c46-979a-d59dfca466c3"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":30,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"tags":["parameters"]}},{"cell_type":"markdown","source":["##### We check if the Delta Table already exists. If it does, we fetch the max date to use as the start date for our data fetching."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# If the table exists, find the max date for incremental load\r\n","if (delta_load == 1 or delta_load is None) and spark._jsparkSession.catalog().tableExists(\"nycgreentaxi\"):\r\n","    max_date_df = spark.sql(\"SELECT MAX(date_key) as max_date FROM nycgreentaxi\")\r\n","    max_date = max_date_df.collect()[0]['max_date']\r\n","    start_date = datetime.combine(max_date, datetime.min.time()) if max_date else parser.parse('2014-05-01')\r\n","    end_date =  start_date + relativedelta.relativedelta(months=1)\r\n","elif (delta_load == 1 or delta_load is None) and not spark._jsparkSession.catalog().tableExists(\"nycgreentaxi\"):\r\n","    start_date = parser.parse(start_date_param)\r\n","    end_date =  start_date + relativedelta.relativedelta(months=1)\r\n","else: # delta_load == 0\r\n","    # For full load, we use the parameter start and end dates\r\n","    start_date = parser.parse(start_date_param)\r\n","    end_date = parser.parse(end_date_param)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-06-18T19:43:06.1967343Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"3de9ab3e-99fa-464f-8317-cea21b7b67df"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":31,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["print(start_date)\r\n","print(end_date)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-06-18T19:43:06.199566Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"a163ff27-de96-444e-a644-4e201dd50814"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["2014-06-01 00:00:00\n2014-07-01 00:00:00\n"]}],"execution_count":32,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["##### We define the schema for our data. This helps ensure that the data types are correct when we load the data into the DataFrame."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# Define the schema for the NYC Green Taxi data\r\n","schema = StructType([\r\n","    StructField('vendorID', IntegerType(), True),\r\n","    StructField('lpepPickupDatetime', TimestampType(), True),\r\n","    StructField('lpepDropoffDatetime', TimestampType(), True),\r\n","    StructField('passengerCount', IntegerType(), True),\r\n","    StructField('tripDistance', DoubleType(), True),\r\n","    StructField('puLocationId', StringType(), True),\r\n","    StructField('doLocationId', StringType(), True),\r\n","    StructField('pickupLongitude', DoubleType(), True),\r\n","    StructField('pickupLatitude', DoubleType(), True),\r\n","    StructField('dropoffLongitude', DoubleType(), True),\r\n","    StructField('dropoffLatitude', DoubleType(), True),\r\n","    StructField('rateCodeID', IntegerType(), True),\r\n","    StructField('storeAndFwdFlag', StringType(), True),\r\n","    StructField('paymentType', IntegerType(), True),\r\n","    StructField('fareAmount', DoubleType(), True),\r\n","    StructField('extra', DoubleType(), True),\r\n","    StructField('mtaTax', DoubleType(), True),\r\n","    StructField('improvementSurcharge', StringType(), True),\r\n","    StructField('tipAmount', DoubleType(), True),\r\n","    StructField('tollsAmount', DoubleType(), True),\r\n","    StructField('ehailFee', DoubleType(), True),\r\n","    StructField('totalAmount', DoubleType(), True),\r\n","    StructField('tripType', DoubleType(), True)\r\n","   \r\n","])"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-06-18T19:43:06.2028909Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"f5a7209f-cf3c-466b-a060-0551d156c029"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":33,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["##### We fetch the data from the Azure Open Dataset for Nyc green taxi and load it into a DataFrame  We then add new columns for year, month, day of month, day of week, hour, and date key and then write the same in to Delta Table."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# Loading data chunk by chunk (1 month at a time)\r\n","while start_date <= end_date:\r\n","    chunk_end_date = min(start_date + relativedelta.relativedelta(months=1), end_date)\r\n","    # Load the data for this chunk\r\n","    nyc_tlc = NycTlcGreen(start_date=start_date, end_date=chunk_end_date)\r\n","    nyc_tlc_df = nyc_tlc.to_s_dataframe()\r\n","    nyc_tlc_df_spark = spark.createDataFrame(nyc_tlc_df, schema)\r\n","\r\n","    # Transform the DataFrame\r\n","    nyc_tlc_df_transformed = nyc_tlc_df_spark.selectExpr(\r\n","        \"*\", \r\n","        \"year(lpepPickupDatetime) as year\",\r\n","        \"month(lpepPickupDatetime) as month\",\r\n","        \"dayofmonth(lpepPickupDatetime) as day_of_month\",\r\n","        \"dayofweek(lpepPickupDatetime) as day_of_week\",\r\n","        \"hour(lpepPickupDatetime) as hour\",\r\n","        \"to_date(lpepPickupDatetime) as date_key\"\r\n","    ).withColumn(\"bronze_loaded_timestamp\", current_timestamp())\r\n","\r\n","    # Writing the transformed data to the Delta table\r\n","    nyc_tlc_df_transformed.write.format('delta').mode(\"append\").saveAsTable(\"nycgreentaxi\")\r\n","\r\n","    # Move the start_date to the next month\r\n","    start_date = chunk_end_date + relativedelta.relativedelta(days=1)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-06-18T19:43:06.2035354Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"88364d29-056f-4c85-8932-58faade84fac"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[Info] read from /tmp/tmp3ds6bbtw/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/green/puYear=2014/puMonth=6/part-00122-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2692-1.c000.snappy.parquet\n"]},{"output_type":"stream","name":"stdout","text":["[Info] read from /tmp/tmp3ds6bbtw/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/green/puYear=2014/puMonth=7/part-00194-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2764-1.c000.snappy.parquet\n"]},{"output_type":"stream","name":"stderr","text":["/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:604: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n"]}],"execution_count":34,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["##### Check the Max date which has been loaded to far"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["df = spark.sql(\"SELECT MAX(date_key) as max_date FROM NYCGreenTaxi\")\n","display(df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-06-18T20:27:30.9376735Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"13dce5d0-75bb-481a-93c7-60d7ea8bee32"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.synapse.widget-view+json":{"widget_id":"0d0805a2-d7af-4fc7-947a-5a1549677625","widget_type":"Synapse.DataFrame"},"text/plain":"SynapseWidget(Synapse.DataFrame, 0d0805a2-d7af-4fc7-947a-5a1549677625)"},"metadata":{}}],"execution_count":35,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false}},{"cell_type":"markdown","source":["##### Maintaince of File Size"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["spark.sql(\"VACUUM bronze_nyc_tlc_green.nycgreentaxi RETAIN 168 HOURS\") \r\n","spark.conf.set(\"spark.databricks.delta.optimize.maxFileSize\", 134217728)  # 128MB\r\n","spark.sql(\"OPTIMIZE bronze_nyc_tlc_green.nycgreentaxi\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-06-18T19:43:06.2054787Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"94843b11-5015-4321-b8f9-0cf9b105c440"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}},{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>>]"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["##### Another method of comparision using delta logs to find the last written date in bronze's delta table"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["Describe_df= spark.sql(\"DESCRIBE history nycgreentaxi\")\r\n","max_write_date = Describe_df.filter(\"operation = 'WRITE'\").agg({\"Timestamp\": \"max\"}).collect()[0][0]\r\n","print(max_write_date)\r\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-06-18T19:43:06.2061892Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"ea233429-69cf-44fa-90f9-fd6699ff62ff"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["2023-06-18 19:44:43.750000\n"]}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["#### Conclusion\r\n","\r\n","##### This notebook demonstrated how to load data from Azure Open Datasets into a Delta Table and perform some basic data transformations. and load data month by month using comparision incrementalload. This provides a scalable and efficient way to handle large amounts of data. From here, we will use the data to move in Silver layer for further enrichment"],"metadata":{"nteract":{"transient":{"deleting":false}}}}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","display_name":"Synapse PySpark"},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{"0d0805a2-d7af-4fc7-947a-5a1549677625":{"type":"Synapse.DataFrame","sync_state":{"table":{"rows":[{"0":"2014-07-01","index":1}],"schema":[{"key":"0","name":"max_date","type":"date"}],"truncated":false},"isSummary":false,"language":"scala"},"persist_state":{"view":{"type":"details","tableOptions":{},"chartOptions":{"chartType":"line","categoryFieldKeys":["0"],"seriesFieldKeys":["0"],"aggregationType":"count","isStacked":false,"binsNumber":10,"wordFrequency":["-1"]}},"customOptions":{}}}}},"trident":{"lakehouse":{"default_lakehouse":"63c3db64-ed42-4d56-9c75-d25ae7abef86","known_lakehouses":[{"id":"63c3db64-ed42-4d56-9c75-d25ae7abef86"}],"default_lakehouse_name":"bronze_nyc_tlc_green","default_lakehouse_workspace_id":"214fe4c8-191c-4f78-8e4a-8d48c3df7147"}}},"nbformat":4,"nbformat_minor":0}